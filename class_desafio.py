import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from imblearn.over_sampling import SMOTE  # Para balanceamento de classes (Passei horas testando pra achar algo que funcionasse rs)

class WineQualityModel:
    """Classe otimizada para classifica√ß√£o bin√°ria de qualidade de vinhos"""
    
    def __init__(self, file_path=None, random_state=42, quality_threshold=6):
        """
        Inicializa o modelo
        Args:
            quality_threshold: Corte para definir vinhos 'bons' (>= threshold) vs 'ruins' (< threshold)
        """
        self.file_path = file_path
        self.random_state = random_state
        self.quality_threshold = quality_threshold  # Define o que √© "vinho bom"
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.model = None

    def load_and_prepare_data(self, data=None, use_smote=True):
        """
        Carrega, transforma e prepara os dados em uma √∫nica fun√ß√£o
        Converte problema multiclasse (3-9) em bin√°rio (0-1)
        """
        # 1. CARREGAR DADOS
        if data is not None:
            self.data = data  # Usar dados fornecidos (dataset combinado)
        else:
            self.data = pd.read_csv(self.file_path, sep=';')  # Carregar do arquivo
        
        # 2. TRANSFORMAR EM PROBLEMA BIN√ÅRIO
        # Cria vari√°vel bin√°ria: 1 = bom (>= threshold), 0 = ruim (< threshold)
        self.data['quality_binary'] = (self.data['quality'] >= self.quality_threshold).astype(int)
        
        # 3. SEPARAR FEATURES E TARGET
        X = self.data.drop(['quality', 'quality_binary'], axis=1, errors='ignore')  # Features (caracter√≠sticas do vinho)
        y = self.data['quality_binary']  # Target bin√°rio (0=ruim, 1=bom)
        
        # 4. DIVIDIR EM TREINO E TESTE
        # Stratify garante que as propor√ß√µes das classes sejam mantidas
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )
        
        # 5. APLICAR SMOTE PARA BALANCEAMENTO (opcional)
        # SMOTE gera amostras sint√©ticas da classe minorit√°ria
        if use_smote:
            try:
                smote = SMOTE(random_state=self.random_state, k_neighbors=5)
                self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)
                print("‚úÖ SMOTE aplicado")
            except:
                print("‚ùå SMOTE falhou, usando class_weight")
                use_smote = False
        
        # 6. MOSTRAR DISTRIBUI√á√ÉO DOS DADOS
        print(f"Dataset: {len(self.data)} amostras | Treino: {len(self.X_train)} | Teste: {len(self.X_test)}")
        binary_dist = self.data['quality_binary'].value_counts()
        print(f"Ruim (< {self.quality_threshold}): {binary_dist[0]} | Bom (>= {self.quality_threshold}): {binary_dist[1]}")
        
        return use_smote

    def train_model(self, smote_applied=False):
        """
        Treina o modelo RandomForest com par√¢metros otimizados
        """
        # Se SMOTE foi aplicado, n√£o usar class_weight (dados j√° balanceados)
        # Sen√£o, usar class_weight='balanced' para lidar com desbalanceamento
        class_weight = None if smote_applied else 'balanced'
        
        # RandomForest com par√¢metros otimizados para vinhos
        self.model = RandomForestClassifier(
            n_estimators=229,        # N√∫mero de √°rvores (mais √°rvores = mais estabilidade)
            max_depth=None,           # Profundidade m√°xima (evita overfitting)
            min_samples_split=3,    # M√≠nimo de amostras para dividir um n√≥
            min_samples_leaf=1,     # M√≠nimo de amostras em uma folha
            max_features='sqrt',    # Considera raiz quadrada das features (bom para alta dimensionalidade)
            bootstrap=True,          # Amostragem com reposi√ß√£o
            class_weight=class_weight,  # Balanceamento autom√°tico se necess√°rio
            random_state=self.random_state
        )
        
        # Treinar o modelo
        self.model.fit(self.X_train, self.y_train)
        print("‚úÖ Modelo treinado")

    def evaluate_model(self):
        """
        Avalia o modelo usando m√©tricas apropriadas para classifica√ß√£o bin√°ria
        """
        # Fazer predi√ß√µes no conjunto de teste
        predictions = self.model.predict(self.X_test)
        
        # Calcular m√©tricas principais
        accuracy = accuracy_score(self.y_test, predictions)    # % acertos totais
        precision = precision_score(self.y_test, predictions)  # % dos "bons" preditos que s√£o realmente bons
        recall = recall_score(self.y_test, predictions)        # % dos "bons" reais que foram identificados
        f1 = f1_score(self.y_test, predictions)               # M√©dia harm√¥nica entre precis√£o e recall
        
        # Mostrar resultados
        print(f"\n=== RESULTADOS ===")
        print(f"Acur√°cia: {accuracy:.1%}")
        print(f"Precis√£o: {precision:.1%}")
        print(f"Recall: {recall:.1%}")
        print(f"F1-Score: {f1:.1%}")
        
        return accuracy, precision, recall, f1

    def plot_results(self):
        """
        Gera visualiza√ß√µes essenciais para interpretar o modelo
        """
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # 1. IMPORT√ÇNCIA DAS CARACTER√çSTICAS
        # Mostra quais caracter√≠sticas s√£o mais importantes para classificar vinhos
        importance = pd.DataFrame({
            'feature': self.X_train.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False).head(8)
        
        axes[0].barh(importance['feature'][::-1], importance['importance'][::-1])
        axes[0].set_title('Top 8 Features Importantes')
        
        # 2. MATRIZ DE CONFUS√ÉO
        # Mostra erros e acertos do modelo
        predictions = self.model.predict(self.X_test)
        cm = confusion_matrix(self.y_test, predictions)
        sns.heatmap(cm, annot=True, fmt='d', ax=axes[1], cmap='Blues',
                   xticklabels=['Ruim', 'Bom'], yticklabels=['Ruim', 'Bom'])
        axes[1].set_title('Matriz de Confus√£o')
        
        # 3. DISTRIBUI√á√ÉO DE PROBABILIDADES
        # Mostra confian√ßa do modelo nas predi√ß√µes
        proba = self.model.predict_proba(self.X_test)[:, 1]  # Probabilidade de ser "bom"
        y_test_array = np.array(self.y_test)
        axes[2].hist(proba[y_test_array == 0], alpha=0.7, label='Ruim', bins=15)
        axes[2].hist(proba[y_test_array == 1], alpha=0.7, label='Bom', bins=15)
        axes[2].axvline(x=0.5, color='red', linestyle='--')  # Linha de decis√£o
        axes[2].set_title('Probabilidades')
        axes[2].legend()
        
        plt.tight_layout()
        plt.show()

# EXECU√á√ÉO PRINCIPAL

if __name__ == "__main__":
    import os
    
    # Encontrar diret√≥rio dos arquivos
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    print("=== CLASSIFICA√á√ÉO BIN√ÅRIA DE VINHOS ===")
    
    # 1. CARREGAR E COMBINAR DATASETS
    # Carregar vinho branco
    white_data = pd.read_csv(os.path.join(base_dir, 'wine+quality', 'winequality-white.csv'), sep=';')
    white_data['type'] = 0  # 0 = vinho branco
    
    # Carregar vinho tinto
    red_data = pd.read_csv(os.path.join(base_dir, 'wine+quality', 'winequality-red.csv'), sep=';')
    red_data['type'] = 1    # 1 = vinho tinto
    
    # Combinar datasets
    combined_data = pd.concat([white_data, red_data], ignore_index=True)
    
    # 2. TREINAR MODELO
    # Criar modelo com threshold 6 (vinhos >= 6 s√£o considerados "bons")
    model = WineQualityModel(quality_threshold=6)
    
    # Carregar dados e aplicar SMOTE para balanceamento
    smote_applied = model.load_and_prepare_data(combined_data, use_smote=True)
    
    # Treinar modelo
    model.train_model(smote_applied)
    
    # 3. AVALIAR E VISUALIZAR
    # Calcular m√©tricas de performance
    accuracy, precision, recall, f1 = model.evaluate_model()
    
    # Gerar gr√°ficos
    model.plot_results()
    
    # 4. MOSTRAR CARACTER√çSTICAS MAIS IMPORTANTES
    # Identificar quais caracter√≠sticas do vinho s√£o mais relevantes
    importance = pd.DataFrame({
        'feature': model.X_train.columns,
        'importance': model.model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nTop 3 caracter√≠sticas importantes:")
    for i, (feature, imp) in enumerate(importance.head(3).values):
        print(f"  {i+1}. {feature}: {imp:.3f}")
    
    print(f"\nüéØ Modelo otimizado para identificar vinhos >= 6!")

# Todos os emojis foram importados do site https://emojiterra.com/
# Minha maior dificuldade foi entender como usar o SMOTE, pois n√£o consegui balancear os dados de treino sem ele. Confesso que o numpy tamb√©m me confunde um pouco...
# Tamb√©m √© a primeira vez que aplico POO em um projeto, ent√£o acredito que esteja BASTANTE confuso e bagun√ßado. Mas farei de tudo para aprimorar meu entendimento no assunto. :)